{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "import datetime\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from architecture import build_unet\n",
    "from pipeline import collect_image_paths, tf_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_files_csv = \"all_files_harmonized.csv\"\n",
    "csv_path = \"data.csv\"\n",
    "batch_size = 2\n",
    "input_shape = (256, 256, 3)\n",
    "epochs = 1\n",
    "lr = 1e-4\n",
    "model_path = \"results/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_vv = collect_image_paths(input_files_csv, img_type=\"vv\")\n",
    "masks_fld = collect_image_paths(input_files_csv, img_type=\"flood_label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('data/train/bangladesh_20170314t115609/tiles/vv/bangladesh_20170314t115609_x-11_y-41_vv.png',\n",
       " 'data/train/bangladesh_20170314t115609/tiles/flood_label/bangladesh_20170314t115609_x-11_y-41.png')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_vv[123], masks_fld[123]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "train_x, test_x = train_test_split(images_vv, test_size=0.2, random_state=112)\n",
    "train_y, test_y = train_test_split(masks_fld, test_size=0.2, random_state=112)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 26724 - 26724\n",
      "Test: 6681 - 6681\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train: {len(train_x)} - {len(train_y)}\")\n",
    "print(f\"Test: {len(test_x)} - {len(test_y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf_dataset(train_x[:1000], train_y[:1000], batch=batch_size)\n",
    "test_dataset = tf_dataset(test_x[:200], test_y[:200], batch=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_unet(input_shape)\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(lr),\n",
    "    metrics=[\n",
    "        tf.keras.metrics.MeanIoU(num_classes=2),\n",
    "        tf.keras.metrics.Recall(),\n",
    "        tf.keras.metrics.Precision()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = os.path.join(model_path, str(datetime.datetime.now()).replace(\" \", \"_\"), \"model.h5\")\n",
    "callbacks = [\n",
    "        ModelCheckpoint(ckpt_path, monitor=\"val_loss\", verbose=1),\n",
    "        ReduceLROnPlateau(monitor=\"val_loss\", patience=5, factor=0.1, verbose=1),\n",
    "        CSVLogger(csv_path),\n",
    "        EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_steps: 13362\n",
      "test_steps: 3341\n"
     ]
    }
   ],
   "source": [
    "train_steps = len(train_x)//batch_size\n",
    "if len(train_x) % batch_size != 0:\n",
    "    train_steps += 1\n",
    "\n",
    "test_steps = len(test_x)//batch_size\n",
    "if len(test_x) % batch_size != 0:\n",
    "    test_steps += 1\n",
    "    \n",
    "print(f\"train_steps: {train_steps}\")\n",
    "print(f\"test_steps: {test_steps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   10/13362 [..............................] - ETA: 24:25:46 - loss: 0.5792 - mean_io_u: 0.4905 - recall: 0.2155 - precision: 0.0148"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "        train_dataset,\n",
    "        validation_data=test_dataset,\n",
    "        epochs=epochs,\n",
    "        steps_per_epoch=train_steps,\n",
    "        validation_steps=test_steps,\n",
    "        callbacks=callbacks\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nasa-impact",
   "language": "python",
   "name": "nasa-impact"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
